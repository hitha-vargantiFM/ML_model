{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Set seeds and environment for reproducibility ---\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'  # Force deterministic GPU ops\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# --- Load both CSVs ---\n",
    "calcs_df = pd.read_csv(\"ABN_MetroExodus_condor_calcs.csv\")\n",
    "raw_df   = pd.read_csv(\"ABN_MetroExodus_raw_condor.csv\")\n",
    "\n",
    "# --- Merge side-by-side (same size, same row order) ---\n",
    "merged_df = pd.concat([calcs_df, raw_df], axis=1)\n",
    "\n",
    "# --- Filter where TestMarker == 0.1 (from calcs file) ---\n",
    "filtered_df = merged_df[merged_df[\"TestMarker\"] == 0.1].reset_index(drop=True)\n",
    "\n",
    "# --- Feature columns ---\n",
    "features = [\n",
    "    \"GT Effective Freq\",\n",
    "    \"GPU_Busy\",\n",
    "    \"GTI_Busy\",\n",
    "    \"PKG Reported Temp\",\n",
    "    \"PKG Reported Power\",\n",
    "    \"hw.raw.RenderBasic.GPU_MEMORY_BYTE_READ\",\n",
    "    \"hw.raw.RenderBasic.GPU_MEMORY_BYTE_WRITE\"\n",
    "]\n",
    "\n",
    "# --- Prepare feature matrix and scale ---\n",
    "X = filtered_df[features].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- Build autoencoder ---\n",
    "input_dim = X_scaled.shape[1]\n",
    "encoding_dim = input_dim // 2 if input_dim > 1 else 1\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "decoder = Dense(input_dim, activation=\"linear\")(encoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# --- Train autoencoder ---\n",
    "autoencoder.fit(\n",
    "    X_scaled, X_scaled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Predict and compute reconstruction errors ---\n",
    "reconstructions = autoencoder.predict(X_scaled)\n",
    "diff = X_scaled - reconstructions\n",
    "\n",
    "# Index of 'GT Effective Freq'\n",
    "freq_idx = features.index('GT Effective Freq')\n",
    "\n",
    "# Frequency-specific reconstruction error and difference\n",
    "freq_recon_error = np.square(diff[:, freq_idx])   # squared errors for freq feature\n",
    "freq_diff = diff[:, freq_idx]                      # signed difference for dip/spike direction\n",
    "\n",
    "# Threshold for anomaly (top 10% error)\n",
    "freq_threshold = np.percentile(freq_recon_error, 85)\n",
    "\n",
    "# Detect dips and spikes based on freq error and direction\n",
    "dip_mask = (freq_recon_error > freq_threshold) & (freq_diff < 0)\n",
    "spike_mask = (freq_recon_error > freq_threshold) & (freq_diff > 0)\n",
    "\n",
    "# Helper function to get continuous index ranges\n",
    "def get_ranges(indexes):\n",
    "    indexes = np.sort(np.unique(indexes))\n",
    "    ranges = []\n",
    "    if len(indexes) > 0:\n",
    "        start = indexes[0]\n",
    "        for prev, curr in zip(indexes, indexes[1:]):\n",
    "            if curr != prev + 1:\n",
    "                ranges.append((start, prev))\n",
    "                start = curr\n",
    "        ranges.append((start, indexes[-1]))\n",
    "    return ranges\n",
    "\n",
    "dip_indexes = np.where(dip_mask)[0]\n",
    "spike_indexes = np.where(spike_mask)\n",
    "\n",
    "dip_ranges = get_ranges(dip_indexes)\n",
    "spike_ranges = get_ranges(spike_indexes)\n",
    "\n",
    "# Format ranges as strings for printing\n",
    "clean_dip_ranges = [f\"{start}-{end}\" for start, end in dip_ranges]\n",
    "clean_spike_ranges = [f\"{start}-{end}\" for start, end in spike_ranges]\n",
    "\n",
    "print(\"Dip ranges:\", clean_dip_ranges)\n",
    "print(\"Spike ranges:\", clean_spike_ranges)\n",
    "\n",
    "# --- Feature influence analysis ---\n",
    "def feature_influence_per_range(df, feature_list, ranges, target_feature):\n",
    "    overall_mean = df[feature_list].mean()\n",
    "    overall_std = df[feature_list].std()\n",
    "\n",
    "    results = []\n",
    "    for start, end in ranges:\n",
    "        subset = df.loc[start:end, feature_list]\n",
    "\n",
    "        mean_diff = subset.mean() - overall_mean\n",
    "        z_scores = mean_diff / overall_std\n",
    "\n",
    "        # exclude the target feature itself\n",
    "        influencers = z_scores.drop(target_feature)\n",
    "\n",
    "        # top 3 influencers by absolute z-score\n",
    "        top_influencers = influencers.abs().sort_values(ascending=False).index[:3]\n",
    "        top_vals = influencers.loc[top_influencers].round(2)\n",
    "\n",
    "        results.append({\n",
    "            \"Range\": f\"{start}-{end}\",\n",
    "            \"Top Influencers\": \", \".join(\n",
    "                [f\"{feat} ({val:+.2f} z)\" for feat, val in zip(top_influencers, top_vals)]\n",
    "            )\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "dip_influencer_table = feature_influence_per_range(filtered_df, features, dip_ranges, 'GT Effective Freq')\n",
    "spike_influencer_table = feature_influence_per_range(filtered_df, features, spike_ranges, 'GT Effective Freq')\n",
    "\n",
    "spike_influencer_table"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
